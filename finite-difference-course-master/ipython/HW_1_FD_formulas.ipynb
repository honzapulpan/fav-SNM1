{
 "metadata": {
  "name": "HW_1_FD_formulas"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we import some standard packages:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pylab as pl\n",
      "import scipy as sp\n",
      "from scipy.misc import factorial"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Deriving and applying finite difference formulas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a function (as described in the text) to compute finite difference coefficients. It uses the Vandermonde matrix formulation.\n",
      "\n",
      "It takes the following inputs:  \n",
      "\n",
      "- $\\mathbf{x}$: a list of points in the stencil  \n",
      "- $k$: the order of the derivative to be approximated  \n",
      "- $\\bar{x}$: the point at which the approximation is to be computed  \n",
      "\n",
      "It returns an array $\\mathbf{c}$, whose elements are the coefficients of the finite difference formula.  Thus  \n",
      "<p style=\"text-align: center;\">$u^{(k)}(\\bar{x}) \\approx \\sum_j c_j u(x_j)$  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fdcoeffV(k,xbar,x):\n",
      "    n=len(x)\n",
      "    A=np.ones([n,n])\n",
      "    xrow=x-xbar\n",
      "    for i in range(1,n):\n",
      "        A[i,:]=xrow**i/factorial(i)\n",
      "    b=np.zeros(n)\n",
      "    b[k]=1\n",
      "    c=np.linalg.solve(A,b)\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code above uses the formula from the text:\n",
      "\n",
      "$$\\left(\\begin{array}{c}  \n",
      " 1 & 1 & \\cdots & 1 \\\\\\\\  \n",
      " x_1-\\bar{x} & x_2 - \\bar{x} & \\cdots & x_n - \\bar{x} \\\\\\\\  \n",
      "\\frac{(x_1-\\bar{x})^2}{2} & \\frac{(x_2 - \\bar{x})^2}{2} & \\cdots & \\frac{(x_n - \\bar{x})^2}{2} \\\\\\\\  \n",
      "\\vdots & \\vdots & \\cdots & \\vdots \\\\\\\\  \n",
      "\\frac{(x_1-\\bar{x})^{n-1}}{(n-1)!} & \\frac{(x_2 - \\bar{x})^{n-1}}{(n-1)!} & \\cdots & \\frac{(x_n - \\bar{x})^{n-1}}{(n-1)!} \\\\\\\\  \n",
      "\\end{array}\\right)\n",
      "\\left(\\begin{array}{c}  \n",
      "c_1 \\\\\\\\ c_2 \\\\\\\\ c_3 \\\\\\\\ \\vdots \\\\\\\\ c_n \\end{array}\\right) =  \n",
      "\\left(\\begin{array}{c}  \n",
      "0 \\\\\\\\ \\vdots \\\\\\\\ 0 \\\\\\\\ 1 \\\\\\\\ 0 \\\\\\\\ \\vdots \\\\\\\\ 0\\end{array}\\right)$$  \n",
      "  \n",
      "Here's an example in which we compute the coefficients of the second-derivative approximation using the points  \n",
      "<p style=\"text-align: center;\">$\\mathbf{x}=[-1,0,1]$:  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=np.arange(-1,2)\n",
      "xbar=0\n",
      "k=2\n",
      "c=fdcoeffV(k,xbar,x)\n",
      "print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we approximate $\\frac{d^2}{dx^2} \\exp(x)$ at $x=0$,  \n",
      "using our formula and the values of $\\exp(x)$ at $x=-1,0,1$:  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fvals=np.exp(x)\n",
      "d2f=np.sum(c*fvals)\n",
      "d2f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercises\n",
      "\n",
      "1) Modify the function <strong>fdcoeffV()</strong> to also return the coefficient of the leading truncation error term.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) Write a script that tests the convergence of a finite difference approximation. Try some approximations of different orders of accuracy, and make a plot like Figure 1.2 on page 6 of the text.  *Hint: use the function plt.loglog()*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3) Run your convergence test using the output of <strong>fdcoeffV</strong> for some very high order approximations. What do you observe?  Can you explain it?  *Hint: try checking the condition number of the Vandermonde matrix, using np.linalg.cond().*\n",
      "\n",
      "<strong>Extra credit: </strong>Set up a function like fdcoeffV() but using sympy's capability for exact linear algebra. Use it to determine the error in the coefficients obtained with fdcoeffV for very high order formulas. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}